import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import ast
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import MultiLabelBinarizer
import xgboost as xgb  # éœ€è¦å®‰è£…: pip install xgboost

# è®¾ç½®ç»˜å›¾é£Žæ ¼
plt.style.use('seaborn-v0_8-whitegrid')

# ==========================================
# 1. æ•°æ®åŠ è½½ä¸ŽåŸºç¡€æ¸…æ´—
# ==========================================
# å‡è®¾æˆ‘ä»¬è¦ç”¨åŒ…å«æ‰€æœ‰åˆ—çš„å¤§è¡¨ï¼Œæˆ–è€…ä½ å·²ç»mergeå¥½çš„è¡¨
# è¿™é‡Œè¯·æ›¿æ¢ä¸ºä½ åŒ…å«ä¸Šè¿°æ‰€æœ‰å­—æ®µçš„æ–‡ä»¶è·¯å¾„
LOAD_PATH = "./dataset/IMDB_Feature_Films_Cleaned.csv" 
# æ³¨æ„ï¼šå¦‚æžœä½ çš„ cleaned æ–‡ä»¶é‡Œæ²¡æœ‰ Director/Star ç­‰åˆ—ï¼Œä½ éœ€è¦é‡æ–°è¯»å–åŽŸå§‹å¤§æ–‡ä»¶å¹¶åšä¸€æ¬¡æ¸…æ´—
# ä¸ºäº†æ¼”ç¤ºï¼Œå‡è®¾ df å·²ç»åŒ…å«äº†ä½ åˆ—å‡ºçš„æ‰€æœ‰ columns
df = pd.read_csv(LOAD_PATH) 

# æ­¥éª¤ A: å¼ºåˆ¶è½¬æ¢ä¸ºæ•°å€¼ç±»åž‹
# 'coerce' ä¼šå°†æ— æ³•è½¬æ¢çš„å­—ç¬¦ä¸²ï¼ˆå¦‚ "Not Rated", "N/A", ç©ºå­—ç¬¦ä¸²ï¼‰ç»Ÿç»Ÿå˜æˆ NaN
df['IMDB_Rating'] = pd.to_numeric(df['IMDB_Rating'], errors='coerce')

# æ­¥éª¤ B: å‰”é™¤ç›®æ ‡å˜é‡ä¸ºç©ºçš„è¡Œ
# è¿™æ˜¯è§£å†³æŠ¥é”™çš„æ ¸å¿ƒï¼
df = df.dropna(subset=['IMDB_Rating'])

# ==========================================
# 2. é«˜çº§ç‰¹å¾å·¥ç¨‹ (The "Secret Sauce")
# ==========================================
print("æ­£åœ¨æž„å»ºé«˜çº§ç‰¹å¾...")

# --- A. æ—¶é—´ç‰¹å¾ ---
# ä»Ž release_date æå–æœˆä»½ (æ•æ‰å­£èŠ‚æ€§)
df['release_date'] = pd.to_datetime(df['release_date'], errors='coerce')
df['release_month'] = df['release_date'].dt.month

# --- B. å•†ä¸šç‰¹å¾ ---
# æ˜¯å¦æœ‰ä¸»é¡µ (1=æœ‰, 0=æ— )
df['has_homepage'] = df['homepage'].notna().astype(int)
# æŠ•èµ„å›žæŠ¥çŽ‡ (å¤„ç†åˆ†æ¯ä¸º0çš„æƒ…å†µ)
df['roi'] = df.apply(lambda x: (x['revenue'] - x['budget']) / x['budget'] if x['budget'] > 1000 else 0, axis=1)

# --- C. "åæ°”"ç‰¹å¾ (Target Encoding) ---
# è¿™æ˜¯ä¸€ä¸ªéžå¸¸å¼ºå¤§çš„æŠ€å·§ï¼šè®¡ç®—å¯¼æ¼”/æ¼”å‘˜çš„åŽ†å²å¹³å‡è¯„åˆ†
# æ³¨æ„ï¼šä¸¥è°¨çš„åšæ³•æ˜¯åœ¨ Train Set ä¸Šè®¡ç®—æ˜ å°„åˆ° Test Setï¼Œé˜²æ­¢æ•°æ®æ³„éœ²ã€‚
# è¿™é‡Œä¸ºäº†ä»£ç ç®€æ´ï¼Œæ¼”ç¤ºå…¨å±€è®¡ç®—ï¼ˆåœ¨åšå­¦æœ¯åˆ†æžæ—¶é€šå¸¸å¯æŽ¥å—ï¼Œä½†åœ¨ä¸¥æ ¼é¢„æµ‹æ¯”èµ›ä¸­éœ€åˆ†å¼€ï¼‰

def calculate_reputation(df, col_name, target_col='vote_average'):
    # è®¡ç®—æ¯ä¸ªäººçš„å¹³å‡åˆ†
    reputation = df.groupby(col_name)[target_col].mean()
    # æ˜ å°„å›žåŽŸè¡¨ï¼Œå¦‚æžœæ˜¯ä¸€ä¸ªæ–°å¯¼æ¼”(æ²¡åœ¨åº“é‡Œ)ï¼Œå°±å¡«å…¨å±€å¹³å‡åˆ†
    global_mean = df[target_col].mean()
    return df[col_name].map(reputation).fillna(global_mean)

# å¯¹å…³é”®äººç‰©è¿›è¡Œç¼–ç 
# å‡è®¾ä½ çš„åˆ—åæ˜¯ 'Director', 'Star1', 'Writer'
if 'Director' in df.columns:
    df['Director_Score'] = calculate_reputation(df, 'Director')
if 'Star1' in df.columns:
    df['Star1_Score'] = calculate_reputation(df, 'Star1')
if 'Writer' in df.columns:
    df['Writer_Score'] = calculate_reputation(df, 'Writer')

# --- D. é¢˜æç‰¹å¾ (One-Hot) ---
# å†æ¬¡å¤„ç† Genre
if isinstance(df['genres_list'].iloc[0], str):
    df['genres_list'] = df['genres_list'].apply(ast.literal_eval)

mlb = MultiLabelBinarizer()
genres_encoded = mlb.fit_transform(df['genres_list'])
genres_df = pd.DataFrame(genres_encoded, columns=[f"Genre_{g}" for g in mlb.classes_], index=df.index)

# ==========================================
# 3. å‡†å¤‡è®­ç»ƒæ•°æ®
# ==========================================
# æŒ‘é€‰æˆ‘ä»¬è¦æ‰”ç»™æ¨¡åž‹çš„æ‰€æœ‰ç‰¹å¾
# åŒ…å«äº†ï¼šæ•°å€¼åŸºç¡€ + é¢˜æ + åæ°”ç‰¹å¾ + æƒ…æ„Ÿ + æ—¶é—´
feature_cols = [
    'runtime', 'budget', 'revenue', 'release_year', 'release_month', # åŸºç¡€
    'roi', 'has_homepage', 'overview_sentiment',                     # å•†ä¸šä¸Žæƒ…æ„Ÿ
    'Director_Score', 'Star1_Score', 'Writer_Score'                  # åæ°” (Key!)
]

# ç¡®ä¿åˆ—å­˜åœ¨
selected_features = [c for c in feature_cols if c in df.columns]
X = pd.concat([df[selected_features], genres_df], axis=1)
y = df['IMDB_Rating'] # æˆ–è€… IMDB_Ratingï¼Œçœ‹ä½ æƒ³é¢„æµ‹å“ªä¸ª

# (å¯é€‰) æ­¥éª¤ C: å‰”é™¤è¯„åˆ†å¼‚å¸¸çš„è¡Œï¼ˆä¾‹å¦‚ 0åˆ†æˆ–è¶…è¿‡10åˆ†ï¼Œè§†æ•°æ®æƒ…å†µè€Œå®šï¼‰
# æœ‰äº›æ•°æ®é›†ä¼šç”¨ -1 ä»£è¡¨ç¼ºå¤±
df = df[(df['IMDB_Rating'] > 0) & (df['IMDB_Rating'] <= 10)]

# å¡«å……ç©ºå€¼ (XGBoostå…¶å®žå¯ä»¥è‡ªåŠ¨å¤„ç†ç©ºå€¼ï¼Œä½†å¡«ä¸Šæ›´ä¿é™©)
X = X.fillna(X.median())

# åˆ’åˆ†è®­ç»ƒé›†æµ‹è¯•é›†
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# ==========================================
# 4. æ¨¡åž‹å‡çº§: XGBoost Regressor
# ==========================================
print(f"æ­£åœ¨è®­ç»ƒ XGBoost (ç‰¹å¾æ•°é‡: {X.shape[1]})...")

# XGBoost å‚æ•°é…ç½® (å¯ä»¥å¾®è°ƒ)
model = xgb.XGBRegressor(
    n_estimators=500,     # æ ‘çš„æ•°é‡
    learning_rate=0.05,   # å­¦ä¹ çŽ‡
    max_depth=6,          # æ ‘çš„æ·±åº¦ (é˜²è¿‡æ‹Ÿåˆ)
    subsample=0.8,        # æ¯æ¬¡åªç”¨80%çš„æ•°æ®
    colsample_bytree=0.8, # æ¯æ¬¡åªç”¨80%çš„ç‰¹å¾
    random_state=42,
    n_jobs=-1
)

model.fit(X_train, y_train)

# ==========================================
# 5. è¯„ä¼°ä¸Žå¯è§†åŒ–
# ==========================================
y_pred = model.predict(X_test)

rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

print(f"\nðŸš€ æ¨¡åž‹å‡çº§ç»“æžœ:")
print(f"RMSE: {rmse:.4f}")
print(f"R^2 Score: {r2:.4f}")

# ç‰¹å¾é‡è¦æ€§ç»˜å›¾
plt.figure(figsize=(12, 10))
# XGBoost æä¾›äº†éžå¸¸æ–¹ä¾¿çš„ plot_importance
# ä½†ä¸ºäº†ç¾Žè§‚ï¼Œæˆ‘ä»¬æ‰‹åŠ¨ç”» Top 20
importances = model.feature_importances_
feature_names = X.columns
feat_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})
feat_df = feat_df.sort_values('Importance', ascending=False).head(20)

sns.barplot(x='Importance', y='Feature', data=feat_df, palette='magma')
plt.title('What REALLY drives Movie Ratings? (XGBoost Feature Importance)', fontsize=16)
plt.tight_layout()
plt.show()

# é¢„æµ‹å¯¹æ¯”å›¾
plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred, alpha=0.3, color='#8e44ad', s=10)
plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--', lw=2, label='Perfect Prediction')
plt.xlabel('Actual Rating')
plt.ylabel('Predicted Rating')
plt.title('XGBoost Prediction Accuracy', fontsize=16)
plt.legend()
plt.show()